{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Needed modules :\n",
    "\n",
    "## Standard :\n",
    "# Full imports :\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import sklearn\n",
    "\n",
    "# Aliased imports :\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Partial Imports :\n",
    "from sys import getsizeof\n",
    "from typing import List, Tuple\n",
    "from scipy import stats\n",
    "from functools import reduce\n",
    "\n",
    "## User-defined :\n",
    "import Preprocessing as pre\n",
    "import Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions :\n",
    "\n",
    "def data_event_filter(df: pd.core.frame.DataFrame, \n",
    "                      undesired_columns: list) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    _tmp = copy.deepcopy(df)\n",
    "    _tmp = _tmp.drop(undesired_columns, axis=1)\n",
    "    _tmp = _tmp.loc[ (_tmp['type'] == 'data') | (_tmp['type'] == 'event') ]\n",
    "    \n",
    "    return _tmp\n",
    "    \n",
    "def time_indexed_df(df1: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \"\"\" Take a return a time-indexed dataframe.\n",
    "    df1 paramater should contain a column called 'dateTime',\n",
    "    which contains entries of type pandas._libs.tslibs.timestamps.Timestamp\n",
    "    \"\"\"\n",
    "    _tmp = copy.deepcopy(df1)\n",
    "    _tmp.index = df1.dateTime\n",
    "    _tmp.drop('dateTime', axis=1, inplace=True)\n",
    "    _tmp = _tmp.sort_index()\n",
    "    gc.collect()\n",
    "    return _tmp\n",
    "\n",
    "\n",
    "def fill_nas(df1: pd.core.frame.DataFrame, \n",
    "             col_names: List[str] = ['activeInsulin', 'carbs', 'insulin', 'trend'],\n",
    "             fill_with=0) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"  Return a new dataframe, replacing all occurrencies of NaNs with \n",
    "    the parameter 'fill_with'.\n",
    "    \"\"\"\n",
    "    _tmp = copy.deepcopy(df1)\n",
    "    for name in col_names:\n",
    "        _tmp[name] = df1[name].fillna(0)\n",
    "    gc.collect()\n",
    "    return _tmp\n",
    "\n",
    "\n",
    "def classify(value: float, limits: Tuple[float, float] = (70, 140)) -> str:\n",
    "    \"\"\" value: Numerical value\n",
    "        limits: Tuple (lower_boundary, high_boundary)\n",
    "        \n",
    "        Returns:\n",
    "            'hypo'  if value < lower_boundary\n",
    "            'normo' if lower_boundary <= value <= high_boundary\n",
    "            'hyper' if value > high_boundary\n",
    "    \"\"\"\n",
    "    if value < limits[0]:\n",
    "        return 'hypo'\n",
    "    elif value > limits[1]:\n",
    "        return 'hyper'\n",
    "    else:\n",
    "        return 'normo'\n",
    "\n",
    "\n",
    "def set_hour(df:  pd.core.frame.DataFrame) ->  pd.core.frame.DataFrame:\n",
    "    \"\"\" Return a copy of 'df', \n",
    "    adding a column called 'hour'.\n",
    "    The dataframe 'df' should be time-indexed.\n",
    "    \"\"\"\n",
    "    _tmp = copy.deepcopy(df)\n",
    "    _tmp.loc[:,'hour'] = list(\n",
    "                             map(\n",
    "                                lambda x: x.hour, df.index\n",
    "                                )\n",
    "                             )\n",
    "    gc.collect()\n",
    "    return _tmp\n",
    "        \n",
    "\n",
    "def set_postprandial(df:  pd.core.frame.DataFrame) ->  pd.core.frame.DataFrame:\n",
    "    \"\"\" Return a copy of 'df', \n",
    "    adding a column called 'hour'.\n",
    "    The dataframe 'df' should be time-indexed.\n",
    "    \"\"\"\n",
    "    _tmp = copy.deepcopy(df)\n",
    "    _tmp.loc[:,'postprandial'] = list(\n",
    "                                     map(\n",
    "                                        lambda x: x.hour + dt.timedelta(hours=2), df.index\n",
    "                                        )\n",
    "                                     )\n",
    "    gc.collect()\n",
    "    return _tmp\n",
    "\n",
    "\n",
    "def tag_glycaemiae(df:  pd.core.frame.DataFrame, \n",
    "                   column_name: str = 'glycaemia') ->  pd.core.frame.DataFrame:\n",
    "    \"\"\" Return a copy of 'df', \n",
    "    adding a column called 'tag'.\n",
    "    See help(classify).\n",
    "    Optional param:\n",
    "        column_name - containing the name of the column\n",
    "                        of glycaemic values\n",
    "        default : 'glycaemia'\n",
    "    \"\"\"\n",
    "    _tmp = copy.deepcopy(df)\n",
    "    _tmp.loc[:,'tag'] = list(\n",
    "                             map(\n",
    "                                classify, df[column_name]\n",
    "                                )\n",
    "                            )\n",
    "    gc.collect()\n",
    "    return _tmp\n",
    "\n",
    "def get_paired_measurements(df:  pd.core.frame.DataFrame, \n",
    "                           column_names: Tuple[str, str] = ('IG', 'BG') ) -> List[Tuple]:\n",
    "    \"\"\" Given a dataframe containing two columns of paired measurements, \n",
    "    return a list of tuples containing the corresponding entries.\n",
    "    This function filters out any measurements which may have a missing observation, \n",
    "    as in (np.nan, 35) or (79.456, np.nan).\n",
    "    \"\"\"\n",
    "    # f := Get paired observations as tuples, or return a tuple of (False, False)\n",
    "    #      to be filtered afterwards\n",
    "    f = lambda x, y: (x, y) if not (np.isnan(x) or np.isnan(y)) else (False, False)\n",
    "    \n",
    "    # g := Return a the given tuple 'x', if and only if both are True\n",
    "    #      which in this context translates to them being numerical values (nonzero).\n",
    "    g = lambda x: x if x[0] and x[1] else False\n",
    "    \n",
    "    _tagged = list(\n",
    "                    map(f, df[column_names[0]], df[column_names[1]])\n",
    "                  )\n",
    "    _paired = list(\n",
    "                    filter(g , _tagged)\n",
    "                  )\n",
    "    return _paired\n",
    "\n",
    "def merge_glycaemic_values(df:  pd.core.frame.DataFrame, drop_na=True,\n",
    "                           column_names: Tuple[str, str] = ('IG', 'BG')) -> pd.core.frame.DataFrame:\n",
    "        \"\"\" Merge the glycaemic values from two specified columns into\n",
    "        a sinlge column 'glycaemia'.\n",
    "        \"\"\"\n",
    "        _tmp = copy.deepcopy(df)\n",
    "        \n",
    "        _tmp[column_names[1]] = list(map(\n",
    "                                    lambda x, y: x if not np.isnan(x) else y, \n",
    "                                    _tmp[column_names[0]], _tmp[column_names[1]]\n",
    "                                ))\n",
    "        _tmp[column_names[0]] = list(map(\n",
    "                                    lambda x, y: x if not np.isnan(x) else y,\n",
    "                                    _tmp[column_names[0]], _tmp[column_names[1]]\n",
    "                                ))  \n",
    "        \n",
    "        _tmp['glycaemia'] = _tmp['IG']\n",
    "        _tmp = _tmp.drop(['IG', 'BG'], axis=1)\n",
    "        if drop_na:\n",
    "            _tmp = _tmp.dropna()\n",
    "        \n",
    "        gc.collect()\n",
    "        return _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Drive.Drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'journal.jl'\n",
    "file_path = os.path.join('data', file_name)\n",
    "d.download(file_name   = file_name, \n",
    "           target_name = file_path\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.file_filter(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal_filtered.jl  journal.jl\r\n"
     ]
    }
   ],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_raw = pd.read_json(file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "undesired_columns = [ \n",
    "    'LOT',\n",
    "    'REF', \n",
    "    'initSuccess', \n",
    "    'secondRound',\n",
    "    'food'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = _raw.drop(undesired_columns, axis=1)\n",
    "_tmp = _tmp.loc[ (_tmp['type'] == 'data') | (_tmp['type'] == 'event') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_tmp = (\\n        _raw.drop(undesired_columns, axis=1)\\n       ).loc[\\n                (_raw['type'] == 'data') |\\n                (_raw['type'] == 'event')\\n            ]\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "_tmp = (\n",
    "        _raw.drop(undesired_columns, axis=1)\n",
    "       ).loc[\n",
    "                (_raw['type'] == 'data') |\n",
    "                (_raw['type'] == 'event')\n",
    "            ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_t_data = time_indexed_df(_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fill_nas(_t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = merge_glycaemic_values(data2)\n",
    "data3 = set_hour(data3)\n",
    "data3 = tag_glycaemiae(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "postp = data3[ data3['details'] == 'Postprandial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "meals = data3[ data3.carbs != 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time :0:00:00.057513\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "real_pairs = []\n",
    "for i in meals.index:\n",
    "    for j in postp.index:\n",
    "        if (i + dt.timedelta(hours=1) < j) and (i + dt.timedelta(hours=3) > j):\n",
    "            real_pairs.append((i, j))\n",
    "end = dt.datetime.now()\n",
    "\n",
    "print(f'Time :{end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time :0:00:00.035662\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "real_pairs = []\n",
    "for i in meals.index:\n",
    "    for j in postp.index:\n",
    "        if (i + dt.timedelta(hours=1) < j) and (i + dt.timedelta(hours=3) > j):\n",
    "            real_pairs.append((i, j))\n",
    "        elif i + dt.timedelta(hours=3) < j:\n",
    "            break\n",
    "end = dt.datetime.now()\n",
    "\n",
    "print(f'Time :{end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_index  = [i[0] for i in real_pairs]\n",
    "postp_index = [i[1] for i in real_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_meals = meals.loc[meal_index, :]\n",
    "filtered_postp = postp.loc[postp_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "meals_idx = filtered_meals.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_idx = filtered_meals[filtered_meals.duplicated()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for dup in duplicate_idx:\n",
    "    indices += [i for i, value in enumerate(meals_idx) if value == dup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_meals = filtered_meals.drop(filtered_postp.index[indices]) # Gives key error even though it shouldn't\n",
    "filtered_meals = filtered_meals.drop_duplicates(keep=False)\n",
    "filtered_postp = filtered_postp.drop(filtered_postp.index[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_postp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_meals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DiabManager]",
   "language": "python",
   "name": "conda-env-DiabManager-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
